<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Maxence Noble </title> <meta name="author" content="Maxence Noble"> <meta name="description" content="Maxence Noble's website. "> <meta name="keywords" content="maxencenoble, sampling, diffusion models, generative models, optimal transport, Schrödinger bridge, mcmc, flow matching"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?7c0eeea1364b1e24b3eb359106aab0b4"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://maxencenoble.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Maxence</span> Noble </h1> <p class="desc"></p> </header> <article> <div class="clearfix"> <p>Hello ! I am currently a second-year PhD candidate in Machine Learning at <a href="https://cmap.ip-paris.fr/" rel="external nofollow noopener" target="_blank">Centre de Mathématiques Appliquées</a> (CMAP) at <a href="https://www.polytechnique.edu/" rel="external nofollow noopener" target="_blank">École Polytechnique</a>, advised by <a href="https://alain.perso.math.cnrs.fr/" rel="external nofollow noopener" target="_blank">Alain Durmus</a>. Prior to this, I graduated with a MSc. degree in Applied Mathematics from École Polytechnique (“<a href="https://programmes.polytechnique.edu/cycle-ingenieur-polytechnicien/cycle-ingenieur-polytechnicien" rel="external nofollow noopener" target="_blank">Cycle Ingénieur</a>”) and a MRes. degree in Mathematics, Vision and Learning (“<a href="https://www.master-mva.com/" rel="external nofollow noopener" target="_blank">MVA</a>”) from <a href="https://ens-paris-saclay.fr/" rel="external nofollow noopener" target="_blank">École Normale Supérieure Paris-Saclay</a>.</p> <p>I am interested in the study of problems at the intersection of generative modelling, sampling, dynamic optimal transport and stochastic optimal control (with a special focus on the <strong>Schrödinger Bridge</strong> problem and <strong>score-based diffusion models</strong>). I am contributing to propose new theoretical perspectives on these subjects as well as developing large-scale algorithms for applications.</p> </div> <h2> <a href="/news/" style="color: inherit">Latest news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 15%">Jun 2024</th> <td> I gave a talk on <a href="https://arxiv.org/pdf/2210.11925" rel="external nofollow noopener" target="_blank">Riemannian constrained sampling</a> at the <a href="https://probabilityrome2024.it/" rel="external nofollow noopener" target="_blank">4-th Italian Meeting on Probability and Mathematical Statistics</a> (Rome, Italy). </td> </tr> <tr> <th scope="row" style="width: 15%">May 2024</th> <td> I presented my latest work <a href="https://arxiv.org/abs/2402.10758" rel="external nofollow noopener" target="_blank">Stochastic Localization via Iterative Posterior Sampling</a> at Google DeepMind’s reading group on generative models, transport and sampling, organized by Valentin de Bortoli. </td> </tr> <tr> <th scope="row" style="width: 15%">May 2024</th> <td> My latest paper <a href="https://arxiv.org/abs/2402.10758" rel="external nofollow noopener" target="_blank">Stochastic Localization via Iterative Posterior Sampling</a> co-authored with Louis Grenioux, Marylou Gabrié and Alain Durmus has been accepted at ICML 2024 (Spotlight, top 3.5%). See you in Vienna in July ! </td> </tr> <tr> <th scope="row" style="width: 15%">Apr 2024</th> <td> I presented my latest work <a href="https://arxiv.org/abs/2402.10758" rel="external nofollow noopener" target="_blank">Stochastic Localization via Iterative Posterior Sampling</a> at <a href="https://bonstats.github.io/mostlymontecarlo/" rel="external nofollow noopener" target="_blank">Mostly Monte Carlo Seminar</a>, organized by Andrea Bertazzi and Joshua Bon (Paris-Santé Campus). </td> </tr> <tr> <th scope="row" style="width: 15%">Apr 2024</th> <td> I am invited to be part of the <a href="https://www.newton.ac.uk/event/dml/" rel="external nofollow noopener" target="_blank">DML programme</a> (<em>Diffusions in machine learning: Foundations, generative models and non-convex optimisation</em>) organised by the Isaac Newton Institute for Mathematical Sciences, which takes place in July 2024 at the Alan Turing Institute. I will give a long talk on my latest work <a href="https://arxiv.org/abs/2402.10758" rel="external nofollow noopener" target="_blank">Stochastic Localization via Iterative Posterior Sampling</a>, bridging gaps between MCMC methods and recent diffusion/flow-based approaches. </td> </tr> <tr> <th scope="row" style="width: 15%">Sep 2023</th> <td> Two of my papers have been accepted at NeurIPS 2023: <a href="https://arxiv.org/pdf/2210.11925" rel="external nofollow noopener" target="_blank">Unbiased constrained sampling with Self-Concordant Barrier Hamiltonian Monte Carlo</a>, co-authored with Valentin de Bortoli and Alain Durmus, and <a href="https://arxiv.org/pdf/2305.16557" rel="external nofollow noopener" target="_blank">Tree-Based Diffusion Schrödinger Bridge with Applications to Wasserstein Barycenters </a>, co-authored with Valentin de Bortoli, Arnaud Doucet and Alain Durmus (Spotlight, top 3.6%). See you in New Orleans in December ! </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">Selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICML</abbr> </div> <div id="grenioux2024stochastic" class="col-sm-8"> <div class="title">Stochastic Localization via Iterative Posterior Sampling</div> <div class="author"> <a href="https://h2o64.github.io/" rel="external nofollow noopener" target="_blank">Louis Grenioux*</a>, <em>Maxence Noble*</em>, <a href="https://marylou-gabrie.github.io/" rel="external nofollow noopener" target="_blank">Marylou Gabrié</a>, and <a href="http://alain.perso.math.cnrs.fr/" rel="external nofollow noopener" target="_blank">Alain Durmus</a> </div> <div class="periodical"> 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Spotlight</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2402.10758" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/h2o64/slips" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://docs.google.com/presentation/d/1lyGKyI2Cis5xIU0-nzsL1kyQnSyJotF8_BiwIAnnVlg/edit?usp=sharing" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>This paper has been selected as a spotlight-designated paper at the conference. Top 3.5% acceptance rate.</p> </div> <div class="abstract hidden"> <p>Building upon score-based learning, new interest in stochastic localization techniques has recently emerged. In these models, one seeks to noise a sample from the data distribution through a stochastic process, called observation process, and progressively learns a denoiser associated to this dynamics. Apart from specific applications, the use of stochastic localization for the problem of sampling from an unnormalized target density has not been explored extensively. This work contributes to fill this gap. We consider a general stochastic localization framework and introduce an explicit class of observation processes, associated with flexible denoising schedules. We provide a complete methodology, Stochastic Localization via Iterative Posterior Sampling (SLIPS), to obtain approximate samples of these dynamics, and as a by-product, samples from the target distribution. Our scheme is based on a Markov chain Monte Carlo estimation of the denoiser and comes with detailed practical guidelines. We illustrate the benefits and applicability of SLIPS on several benchmarks, including Gaussian mixtures in increasing dimensions, Bayesian logistic regression and a high-dimensional field system from statistical-mechanics.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> </div> <div id="noble2024tree" class="col-sm-8"> <div class="title">Tree-based Diffusion Schrödinger Bridge with Applications to Wasserstein Barycenters</div> <div class="author"> <em>Maxence Noble</em>, <a href="https://vdeborto.github.io/" rel="external nofollow noopener" target="_blank">Valentin De Bortoli</a>, <a href="https://www.stats.ox.ac.uk/~doucet/" rel="external nofollow noopener" target="_blank">Arnaud Doucet</a>, and <a href="http://alain.perso.math.cnrs.fr/" rel="external nofollow noopener" target="_blank">Alain Durmus</a> </div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Spotlight</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2305.16557" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/maxencenoble/tree-diffusion-schrodinger-bridge" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/TreeDSB_slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>This paper has been selected as a spotlight-designated paper at the conference. Top 3.6% acceptance rate.</p> </div> <div class="abstract hidden"> <p>Multi-marginal Optimal Transport (mOT), a generalization of OT, aims at minimizing the integral of a cost function with respect to a distribution with some prescribed marginals. In this paper, we consider an entropic version of mOT with a tree-structured quadratic cost, i.e., a function that can be written as a sum of pairwise cost functions between the nodes of a tree. To address this problem, we develop Tree-based Diffusion Schrödinger Bridge (TreeDSB), an extension of the Diffusion Schrödinger Bridge (DSB) algorithm. TreeDSB corresponds to a dynamic and continuous state-space counterpart of the multimarginal Sinkhorn algorithm. A notable use case of our methodology is to compute Wasserstein barycenters which can be recast as the solution of a mOT problem on a star-shaped tree. We demonstrate that our methodology can be applied in high-dimensional settings such as image interpolation and Bayesian fusion.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> </div> <div id="noble2024unbiased" class="col-sm-8"> <div class="title">Unbiased constrained sampling with Self-Concordant Barrier Hamiltonian Monte Carlo</div> <div class="author"> <em>Maxence Noble</em>, <a href="https://vdeborto.github.io/" rel="external nofollow noopener" target="_blank">Valentin De Bortoli</a>, and <a href="http://alain.perso.math.cnrs.fr/" rel="external nofollow noopener" target="_blank">Alain Durmus</a> </div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2210.11925" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/maxencenoble/barrier-hamiltonian-monte-carlo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/BHMC_slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>In this paper, we propose Barrier Hamiltonian Monte Carlo (BHMC), a version of the HMC algorithm which aims at sampling from a Gibbs distribution π on a manifold M, endowed with a Hessian metric 𝔤 derived from a self-concordant barrier. Our method relies on Hamiltonian dynamics which comprises 𝔤. Therefore, it incorporates the constraints defining M and is able to exploit its underlying geometry. However, the corresponding Hamiltonian dynamics is defined via non separable Ordinary Differential Equations (ODEs) in contrast to the Euclidean case. It implies unavoidable bias in existing generalization of HMC to Riemannian manifolds. In this paper, we propose a new filter step, called "involution checking step", to address this problem. This step is implemented in two versions of BHMC, coined continuous BHMC (c-BHMC) and numerical BHMC (n-BHMC) respectively. Our main results establish that these two new algorithms generate reversible Markov chains with respect to π and do not suffer from any bias in comparison to previous implementations. Our conclusions are supported by numerical experiments where we consider target distributions defined on polytopes.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AISTATS</abbr> </div> <div id="noble2022differentially" class="col-sm-8"> <div class="title">Differentially private Federated Learning on heterogeneous data</div> <div class="author"> <em>Maxence Noble</em>, <a href="http://researchers.lille.inria.fr/abellet/" rel="external nofollow noopener" target="_blank">Aurélien Bellet</a>, and <a href="http://www.cmap.polytechnique.fr/~aymeric.dieuleveut/" rel="external nofollow noopener" target="_blank">Aymeric Dieuleveut</a> </div> <div class="periodical"> 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2111.09278" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/maxencenoble/Differential-Privacy-for-Heterogeneous-Federated-Learning" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Federated Learning (FL) is a paradigm for large-scale distributed learning which faces two key challenges: (i) efficient training from highly heterogeneous user data, and (ii) protecting the privacy of participating users. In this work, we propose a novel FL approach (DP-SCAFFOLD) to tackle these two challenges together by incorporating Differential Privacy (DP) constraints into the popular SCAFFOLD algorithm. We focus on the challenging setting where users communicate with a "honest-but-curious" server without any trusted intermediary, which requires to ensure privacy not only towards a third-party with access to the final model but also towards the server who observes all user communications. Using advanced results from DP theory, we establish the convergence of our algorithm for convex and non-convex objectives. Our analysis clearly highlights the privacy-utility trade-off under data heterogeneity, and demonstrates the superiority of DP-SCAFFOLD over the state-of-the-art algorithm DP-FedAvg when the number of local updates and the level of heterogeneity grow. Our numerical results confirm our analysis and show that DP-SCAFFOLD provides significant gains in practice.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6D%61%78%65%6E%63%65.%6E%6F%62%6C%65-%62%6F%75%72%69%6C%6C%6F%74@%70%6F%6C%79%74%65%63%68%6E%69%71%75%65.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=4eGHx3gAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/maxencenoble" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/maxence-noble" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> </div> <div class="contact-note">Feel free to contact me by email ! </div> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 Maxence Noble. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: June 17, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?06cae41083477f121be8cd9797ad8e2f"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>